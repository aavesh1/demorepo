{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyimagesearch.smallervggnet import SmallerVGGNet\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\"dataset\":\"C:/Users/naveen.dagar/start_learning_python/covid19-multi-level/dataset\",\n",
    "     \"model\":\"C:/Users/naveen.dagar/start_learning_python/covid19-multi-level/covid19.model\",\n",
    "     \"labelbin\":\"C:/Users/naveen.dagar/start_learning_python/covid19-multi-level/mlb.pickle\",\n",
    "     \"plot\":\"C:/Users/naveen.dagar/start_learning_python/covid19-multi-level/plot.png\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "EPOCHS = 75\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMAGE_DIMS = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# grab the image paths and randomly shuffle them\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = sorted(list(paths.list_images(args[\"dataset\"])))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# initialize the data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "\n",
    "    # extract set of class labels from the image path and update the\n",
    "    # labels list\n",
    "    l = label = imagePath.split(os.path.sep)[-2].split(\"_\")\n",
    "    labels.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 298 images (350.45MB)\n",
      "[INFO] class labels:\n",
      "1. covid\n",
      "2. normal\n"
     ]
    }
   ],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(\n",
    "    len(imagePaths), data.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "# binarize the labels using scikit-learn's special multi-label\n",
    "# binarizer implementation\n",
    "print(\"[INFO] class labels:\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(labels)\n",
    "\n",
    "# loop over each of the possible class labels and show them\n",
    "for (i, label) in enumerate(mlb.classes_):\n",
    "    print(\"{}. {}\".format(i + 1, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "    labels, test_size=0.2, random_state=42)\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "WARNING:tensorflow:From C:\\Users\\naveen.dagar\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# initialize the model using a sigmoid activation as the final layer\n",
    "# in the network so we can perform multi-label classification\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = SmallerVGGNet.build(\n",
    "    width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "    depth=IMAGE_DIMS[2], classes=len(mlb.classes_),\n",
    "    finalAct=\"sigmoid\")\n",
    "# initialize the optimizer\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "WARNING:tensorflow:From C:\\Users\\naveen.dagar\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/75\n",
      "7/7 [==============================] - 130s 19s/step - loss: 1.1066 - accuracy: 0.5898 - val_loss: 0.4663 - val_accuracy: 0.9333\n",
      "Epoch 2/75\n",
      "7/7 [==============================] - 123s 18s/step - loss: 0.7552 - accuracy: 0.6238 - val_loss: 0.2865 - val_accuracy: 0.9333\n",
      "Epoch 3/75\n",
      "7/7 [==============================] - 122s 17s/step - loss: 0.6497 - accuracy: 0.6917 - val_loss: 0.3010 - val_accuracy: 0.9333\n",
      "Epoch 4/75\n",
      "7/7 [==============================] - 135s 19s/step - loss: 0.5580 - accuracy: 0.7188 - val_loss: 0.3975 - val_accuracy: 0.9333\n",
      "Epoch 5/75\n",
      "7/7 [==============================] - 124s 18s/step - loss: 0.4960 - accuracy: 0.7840 - val_loss: 0.2820 - val_accuracy: 0.9333\n",
      "Epoch 6/75\n",
      "7/7 [==============================] - 127s 18s/step - loss: 0.4271 - accuracy: 0.8422 - val_loss: 0.3203 - val_accuracy: 0.9417\n",
      "Epoch 7/75\n",
      "7/7 [==============================] - 129s 18s/step - loss: 0.4076 - accuracy: 0.8471 - val_loss: 0.9879 - val_accuracy: 0.5000\n",
      "Epoch 8/75\n",
      "7/7 [==============================] - 125s 18s/step - loss: 0.3571 - accuracy: 0.8617 - val_loss: 0.8099 - val_accuracy: 0.1333\n",
      "Epoch 9/75\n",
      "7/7 [==============================] - 144s 21s/step - loss: 0.2823 - accuracy: 0.9196 - val_loss: 1.5240 - val_accuracy: 0.0667\n",
      "Epoch 10/75\n",
      "7/7 [==============================] - 114s 16s/step - loss: 0.2884 - accuracy: 0.9096 - val_loss: 1.1471 - val_accuracy: 0.0667\n",
      "Epoch 11/75\n",
      "7/7 [==============================] - 122s 17s/step - loss: 0.4337 - accuracy: 0.8839 - val_loss: 0.7861 - val_accuracy: 0.5000\n",
      "Epoch 12/75\n",
      "7/7 [==============================] - 105s 15s/step - loss: 0.3647 - accuracy: 0.8617 - val_loss: 1.6424 - val_accuracy: 0.5000\n",
      "Epoch 13/75\n",
      "7/7 [==============================] - 121s 17s/step - loss: 0.3328 - accuracy: 0.8728 - val_loss: 1.1784 - val_accuracy: 0.4917\n",
      "Epoch 14/75\n",
      "7/7 [==============================] - 112s 16s/step - loss: 0.2537 - accuracy: 0.9005 - val_loss: 0.4344 - val_accuracy: 0.9250\n",
      "Epoch 15/75\n",
      "7/7 [==============================] - 110s 16s/step - loss: 0.3994 - accuracy: 0.8762 - val_loss: 0.4811 - val_accuracy: 0.8583\n",
      "Epoch 16/75\n",
      "7/7 [==============================] - 111s 16s/step - loss: 0.2545 - accuracy: 0.9029 - val_loss: 0.2803 - val_accuracy: 0.9250\n",
      "Epoch 17/75\n",
      "7/7 [==============================] - 110s 16s/step - loss: 0.2922 - accuracy: 0.9029 - val_loss: 0.1113 - val_accuracy: 0.9583\n",
      "Epoch 18/75\n",
      "7/7 [==============================] - 111s 16s/step - loss: 0.2996 - accuracy: 0.8883 - val_loss: 0.1617 - val_accuracy: 0.9417\n",
      "Epoch 19/75\n",
      "7/7 [==============================] - 111s 16s/step - loss: 0.2608 - accuracy: 0.9175 - val_loss: 0.1255 - val_accuracy: 0.9500\n",
      "Epoch 20/75\n",
      "7/7 [==============================] - 120s 17s/step - loss: 0.2643 - accuracy: 0.9018 - val_loss: 0.0817 - val_accuracy: 0.9500\n",
      "Epoch 21/75\n",
      "7/7 [==============================] - 111s 16s/step - loss: 0.2022 - accuracy: 0.9272 - val_loss: 0.1471 - val_accuracy: 0.9500\n",
      "Epoch 22/75\n",
      "7/7 [==============================] - 111s 16s/step - loss: 0.1791 - accuracy: 0.9199 - val_loss: 0.3075 - val_accuracy: 0.9250\n",
      "Epoch 23/75\n",
      "7/7 [==============================] - 111s 16s/step - loss: 0.2909 - accuracy: 0.9393 - val_loss: 0.2593 - val_accuracy: 0.9000\n",
      "Epoch 24/75\n",
      "7/7 [==============================] - 111s 16s/step - loss: 0.1314 - accuracy: 0.9539 - val_loss: 0.4025 - val_accuracy: 0.9333\n",
      "Epoch 25/75\n",
      "7/7 [==============================] - 109s 16s/step - loss: 0.1419 - accuracy: 0.9369 - val_loss: 0.2657 - val_accuracy: 0.9167\n",
      "Epoch 26/75\n",
      "7/7 [==============================] - 113s 16s/step - loss: 0.1776 - accuracy: 0.9320 - val_loss: 0.2785 - val_accuracy: 0.8917\n",
      "Epoch 27/75\n",
      "7/7 [==============================] - 121s 17s/step - loss: 0.0984 - accuracy: 0.9587 - val_loss: 0.3030 - val_accuracy: 0.9000\n",
      "Epoch 28/75\n",
      "7/7 [==============================] - 124s 18s/step - loss: 0.1257 - accuracy: 0.9576 - val_loss: 0.3210 - val_accuracy: 0.9000\n",
      "Epoch 29/75\n",
      "7/7 [==============================] - 111s 16s/step - loss: 0.1025 - accuracy: 0.9660 - val_loss: 0.3352 - val_accuracy: 0.9000\n",
      "Epoch 30/75\n",
      "7/7 [==============================] - 112s 16s/step - loss: 0.1412 - accuracy: 0.9393 - val_loss: 0.3406 - val_accuracy: 0.9333\n",
      "Epoch 31/75\n",
      "7/7 [==============================] - 111s 16s/step - loss: 0.0983 - accuracy: 0.9636 - val_loss: 0.3539 - val_accuracy: 0.9250\n",
      "Epoch 32/75\n",
      "7/7 [==============================] - 112s 16s/step - loss: 0.1115 - accuracy: 0.9563 - val_loss: 0.2718 - val_accuracy: 0.8917\n",
      "Epoch 33/75\n",
      "7/7 [==============================] - 109s 16s/step - loss: 0.1315 - accuracy: 0.9563 - val_loss: 0.3346 - val_accuracy: 0.9000\n",
      "Epoch 34/75\n",
      "7/7 [==============================] - 111s 16s/step - loss: 0.1204 - accuracy: 0.9539 - val_loss: 0.2382 - val_accuracy: 0.9000\n",
      "Epoch 35/75\n",
      "7/7 [==============================] - 119s 17s/step - loss: 0.1417 - accuracy: 0.9487 - val_loss: 0.2459 - val_accuracy: 0.9083\n",
      "Epoch 36/75\n",
      "7/7 [==============================] - 103s 15s/step - loss: 0.0937 - accuracy: 0.9601 - val_loss: 0.2011 - val_accuracy: 0.9333\n",
      "Epoch 37/75\n",
      "7/7 [==============================] - 119s 17s/step - loss: 0.1118 - accuracy: 0.9554 - val_loss: 0.2646 - val_accuracy: 0.9333\n",
      "Epoch 38/75\n",
      "7/7 [==============================] - 102s 15s/step - loss: 0.0669 - accuracy: 0.9734 - val_loss: 0.3011 - val_accuracy: 0.9333\n",
      "Epoch 39/75\n",
      "7/7 [==============================] - 112s 16s/step - loss: 0.0847 - accuracy: 0.9636 - val_loss: 0.3565 - val_accuracy: 0.9333\n",
      "Epoch 40/75\n",
      "7/7 [==============================] - 121s 17s/step - loss: 0.0687 - accuracy: 0.9777 - val_loss: 0.2093 - val_accuracy: 0.9000\n",
      "Epoch 41/75\n",
      "7/7 [==============================] - 118s 17s/step - loss: 0.0677 - accuracy: 0.9777 - val_loss: 0.2544 - val_accuracy: 0.9083\n",
      "Epoch 42/75\n",
      "7/7 [==============================] - 103s 15s/step - loss: 0.0456 - accuracy: 0.9894 - val_loss: 0.1534 - val_accuracy: 0.9333\n",
      "Epoch 43/75\n",
      "7/7 [==============================] - 111s 16s/step - loss: 0.0470 - accuracy: 0.9854 - val_loss: 0.1712 - val_accuracy: 0.9333\n",
      "Epoch 44/75\n",
      "7/7 [==============================] - 120s 17s/step - loss: 0.1032 - accuracy: 0.9688 - val_loss: 0.2545 - val_accuracy: 0.9000\n",
      "Epoch 45/75\n",
      "7/7 [==============================] - 116s 17s/step - loss: 0.0333 - accuracy: 0.9927 - val_loss: 0.3092 - val_accuracy: 0.9083\n",
      "Epoch 46/75\n",
      "7/7 [==============================] - 117s 17s/step - loss: 0.0458 - accuracy: 0.9830 - val_loss: 0.3386 - val_accuracy: 0.8917\n",
      "Epoch 47/75\n",
      "7/7 [==============================] - 117s 17s/step - loss: 0.0610 - accuracy: 0.9830 - val_loss: 0.3320 - val_accuracy: 0.8917\n",
      "Epoch 48/75\n",
      "7/7 [==============================] - 118s 17s/step - loss: 0.0640 - accuracy: 0.9733 - val_loss: 0.2685 - val_accuracy: 0.9000\n",
      "Epoch 49/75\n",
      "7/7 [==============================] - 115s 16s/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 0.2618 - val_accuracy: 0.8917\n",
      "Epoch 50/75\n",
      "7/7 [==============================] - 126s 18s/step - loss: 0.0572 - accuracy: 0.9799 - val_loss: 0.3035 - val_accuracy: 0.9000\n",
      "Epoch 51/75\n",
      "7/7 [==============================] - 108s 15s/step - loss: 0.0739 - accuracy: 0.9707 - val_loss: 0.3319 - val_accuracy: 0.9083\n",
      "Epoch 52/75\n",
      "7/7 [==============================] - 117s 17s/step - loss: 0.1096 - accuracy: 0.9709 - val_loss: 0.3560 - val_accuracy: 0.9083\n",
      "Epoch 53/75\n",
      "7/7 [==============================] - 126s 18s/step - loss: 0.0872 - accuracy: 0.9621 - val_loss: 0.5382 - val_accuracy: 0.8417\n",
      "Epoch 54/75\n",
      "7/7 [==============================] - 108s 15s/step - loss: 0.0618 - accuracy: 0.9787 - val_loss: 0.5626 - val_accuracy: 0.8250\n",
      "Epoch 55/75\n",
      "7/7 [==============================] - 119s 17s/step - loss: 0.0623 - accuracy: 0.9782 - val_loss: 0.3587 - val_accuracy: 0.9000\n",
      "Epoch 56/75\n",
      "7/7 [==============================] - 126s 18s/step - loss: 0.0831 - accuracy: 0.9732 - val_loss: 0.3075 - val_accuracy: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/75\n",
      "7/7 [==============================] - 115s 16s/step - loss: 0.0423 - accuracy: 0.9879 - val_loss: 0.2509 - val_accuracy: 0.9250\n",
      "Epoch 58/75\n",
      "7/7 [==============================] - 117s 17s/step - loss: 0.0745 - accuracy: 0.9757 - val_loss: 0.3952 - val_accuracy: 0.9083\n",
      "Epoch 59/75\n",
      "7/7 [==============================] - 128s 18s/step - loss: 0.0540 - accuracy: 0.9854 - val_loss: 0.2900 - val_accuracy: 0.9250\n",
      "Epoch 60/75\n",
      "7/7 [==============================] - 126s 18s/step - loss: 0.0667 - accuracy: 0.9754 - val_loss: 0.2640 - val_accuracy: 0.9500\n",
      "Epoch 61/75\n",
      "7/7 [==============================] - 108s 15s/step - loss: 0.0345 - accuracy: 0.9840 - val_loss: 0.2679 - val_accuracy: 0.9250\n",
      "Epoch 62/75\n",
      "7/7 [==============================] - 127s 18s/step - loss: 0.0159 - accuracy: 0.9978 - val_loss: 0.2460 - val_accuracy: 0.9333\n",
      "Epoch 63/75\n",
      "7/7 [==============================] - 117s 17s/step - loss: 0.0631 - accuracy: 0.9806 - val_loss: 0.2147 - val_accuracy: 0.9500\n",
      "Epoch 64/75\n",
      "7/7 [==============================] - 116s 17s/step - loss: 0.0512 - accuracy: 0.9854 - val_loss: 0.2044 - val_accuracy: 0.9500\n",
      "Epoch 65/75\n",
      "7/7 [==============================] - 114s 16s/step - loss: 0.0706 - accuracy: 0.9782 - val_loss: 0.1209 - val_accuracy: 0.9667\n",
      "Epoch 66/75\n",
      "7/7 [==============================] - 119s 17s/step - loss: 0.0316 - accuracy: 0.9927 - val_loss: 0.1481 - val_accuracy: 0.9333\n",
      "Epoch 67/75\n",
      "7/7 [==============================] - 117s 17s/step - loss: 0.0303 - accuracy: 0.9903 - val_loss: 0.2926 - val_accuracy: 0.8750\n",
      "Epoch 68/75\n",
      "7/7 [==============================] - 113s 16s/step - loss: 0.0578 - accuracy: 0.9830 - val_loss: 0.2080 - val_accuracy: 0.9250\n",
      "Epoch 69/75\n",
      "7/7 [==============================] - 121s 17s/step - loss: 0.0372 - accuracy: 0.9844 - val_loss: 0.1487 - val_accuracy: 0.9417\n",
      "Epoch 70/75\n",
      "7/7 [==============================] - 111s 16s/step - loss: 0.0268 - accuracy: 0.9879 - val_loss: 0.0463 - val_accuracy: 0.9750\n",
      "Epoch 71/75\n",
      "7/7 [==============================] - 117s 17s/step - loss: 0.0301 - accuracy: 0.9927 - val_loss: 0.0630 - val_accuracy: 0.9750\n",
      "Epoch 72/75\n",
      "7/7 [==============================] - 111s 16s/step - loss: 0.1024 - accuracy: 0.9709 - val_loss: 0.1137 - val_accuracy: 0.9500\n",
      "Epoch 73/75\n",
      "7/7 [==============================] - 118s 17s/step - loss: 0.0439 - accuracy: 0.9844 - val_loss: 0.1339 - val_accuracy: 0.9417\n",
      "Epoch 74/75\n",
      "7/7 [==============================] - 104s 15s/step - loss: 0.0487 - accuracy: 0.9787 - val_loss: 0.2169 - val_accuracy: 0.9333\n",
      "Epoch 75/75\n",
      "7/7 [==============================] - 120s 17s/step - loss: 0.0288 - accuracy: 0.9888 - val_loss: 0.2024 - val_accuracy: 0.9250\n"
     ]
    }
   ],
   "source": [
    "# compile the model using binary cross-entropy rather than\n",
    "# categorical cross-entropy -- this may seem counterintuitive for\n",
    "# multi-label classification, but keep in mind that the goal here\n",
    "# is to treat each output label as an independent Bernoulli\n",
    "# distribution\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing CNN network...\n",
      "[INFO] serializing label binarizer...\n"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] serializing CNN network...\")\n",
    "model.save(args[\"model\"])\n",
    "\n",
    "# save the multi-label binarizer to disk\n",
    "print(\"[INFO] serializing label binarizer...\")\n",
    "f = open(args[\"labelbin\"], \"wb\")\n",
    "f.write(pickle.dumps(mlb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
